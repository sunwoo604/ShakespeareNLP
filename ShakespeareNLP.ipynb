{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fb1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfec964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "temp = []\n",
    "for i in open('shakespeare.txt'):\n",
    "    s = i.lower().lstrip()\n",
    "    if len(s.split())<2:\n",
    "        if len(temp) >0:\n",
    "            data.append(temp)\n",
    "        temp = []\n",
    "        continue\n",
    "    temp.append(s)\n",
    "data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75be32d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b69d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.api import *\n",
    "from nltk.corpus.reader.util import *\n",
    "from nltk.util import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757dfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "from nltk.tokenize import sent_tokenize,wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da9013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9871cca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /home/suk012/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae4c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9c6ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "['F', 'R', 'AH1', 'M']\n",
      "fairest\n",
      "['F', 'EH1', 'R', 'IH0', 'S', 'T']\n",
      "creatures\n",
      "['K', 'R', 'IY1', 'CH', 'ER0', 'Z']\n",
      "we\n",
      "['W', 'IY1']\n",
      "desire\n",
      "['D', 'IH0', 'Z', 'AY1', 'ER0']\n",
      "increase\n",
      "['IH0', 'N', 'K', 'R', 'IY1', 'S']\n"
     ]
    }
   ],
   "source": [
    "for i in data[0][0].split():\n",
    "    temp = i.translate(str.maketrans('', '', string.punctuation))\n",
    "    print(temp)\n",
    "    print(cd[temp][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe05684",
   "metadata": {},
   "outputs": [],
   "source": [
    "##syllable tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb77f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllDict = {}\n",
    "for i in open('Syllable_dictionary.txt'):\n",
    "    temp = i.split()\n",
    "    syllDict[temp[0]] = temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c50823f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for d in data:\n",
    "    for i in d:\n",
    "        words+=wordpunct_tokenize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a086d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=(list(set(words)))+['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f07a1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_idx = {w:i for i,w in enumerate(words)}\n",
    "idx_words = {i:w for i,w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8770ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = []\n",
    "for d in data:\n",
    "    temp = []\n",
    "    for i in d:\n",
    "        temp+=wordpunct_tokenize(i)+['\\n']\n",
    "    data_word.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f851a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(data_word):\n",
    "    temp = []\n",
    "    for w in d:\n",
    "        temp.append(words_idx[w])\n",
    "    data_word[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84654ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_words = []\n",
    "for d in words:\n",
    "    temp = []\n",
    "    for i in words:\n",
    "        if i in syllDict:\n",
    "            temp.append(int(syllDict[i][-1]))\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    syll_words.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad546993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## character level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ff1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set()\n",
    "for i in data:\n",
    "    temp = \"\"\n",
    "    for j in i:\n",
    "        temp=temp+j\n",
    "    chars = chars.union(set(list(temp)))\n",
    "chars = sorted(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4f382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b043fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75d34c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee621db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i, s in enumerate(data):\n",
    "    \n",
    "    temp =\"\"\n",
    "    for l in s:\n",
    "        temp+=l\n",
    "    temp = list(temp)\n",
    "    for j, ch in enumerate(temp):\n",
    "        temp[j] = char_to_ix[ch]\n",
    "    dataset.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32baede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, output_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        #self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        #output = self.softmax(output)\n",
    "        return output, (hidden_state[0], hidden_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08083d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=len(chars), embedding_size=len(chars), output_size=len(chars), hidden_size=256).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())#, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa8a3593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:22<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Loss: 1.78435286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \t Loss: 1.58508797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:21<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \t Loss: 1.51682984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:22<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \t Loss: 1.47270482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:26<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Loss: 1.43533315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:20<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \t Loss: 1.40608571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:59<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \t Loss: 1.37885479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:22<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \t Loss: 1.35620974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \t Loss: 1.33539440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t Loss: 1.31951436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \t Loss: 1.30361331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:22<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \t Loss: 1.29312238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:23<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \t Loss: 1.27742322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:25<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \t Loss: 1.26237014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \t Loss: 1.25514320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \t Loss: 1.24616098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \t Loss: 1.23942875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:23<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \t Loss: 1.23226866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \t Loss: 1.22587442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:24<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \t Loss: 1.21745815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for i_epoch in range(1, epochs+1):\n",
    "        \n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    for d in tqdm(range(len(dataset))):\n",
    "        d = torch.tensor(dataset[d]).to(device)\n",
    "        for i in range(40,len(d)-1,7):\n",
    "            hidden_state = None\n",
    "            input_seq = d[i-40 : i]\n",
    "            target_seq = d[i-40+1 : i+1]\n",
    "            # forward pass\n",
    "            output, _ = model(input_seq, hidden_state)\n",
    "            #print(input_seq,target_seq,output)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq)) \n",
    "            running_loss += loss.item()\n",
    "            n += 1\n",
    "\n",
    "            # compute gradients and take optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print loss after every epoch\n",
    "    print(\"Epoch: {0} \\t Loss: {1:.8f}\".format(i_epoch, running_loss/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a0bd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964/1361728061.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prompt = torch.tensor(prompt).to(device).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and by and loving the brave mine eyes to\n",
      "\n",
      "for T: 0.25\n",
      "\n",
      " prevawers i am not enloten,\n",
      "that i do i\n",
      "\n",
      "for T: 0.75\n",
      "\n",
      " hall eyes the store,\n",
      "and live, the lere\n",
      "\n",
      "for T: 1\n",
      "\n",
      "rtai advanfuupt it,\n",
      "and i bold the stray\n",
      "\n",
      "for T: 1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"shall i compare thee to a summer's day\\n\"\n",
    "prompt = list(prompt)\n",
    "for i, ch in enumerate(prompt):\n",
    "    prompt[i] = char_to_ix[ch]\n",
    "for t in [0.25,0.75,1,1.5]:\n",
    "    with torch.no_grad():\n",
    "        prompt = torch.tensor(prompt).to(device).long()\n",
    "        hidden_state = None\n",
    "\n",
    "        for _ in range(40):\n",
    "\n",
    "             # forward pass\n",
    "            output, hidden_state = model(prompt, hidden_state)\n",
    "\n",
    "            # construct categorical distribution and sample a character\n",
    "            output = F.softmax(torch.squeeze(output[-1]/t), dim=0)\n",
    "            dist = Categorical(output)\n",
    "            index = dist.sample()\n",
    "\n",
    "            # print the sampled character\n",
    "            print(ix_to_char[index.item()], end='')\n",
    "\n",
    "            # next input is current output\n",
    "            prompt = torch.cat([prompt[1:], index.unsqueeze(0)])\n",
    "        print()\n",
    "        print()\n",
    "        print('for T: '+str(t))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97efe414",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e92c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ff5001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, output_size, hidden_size):\n",
    "        super(wordRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, (hidden_state[0], hidden_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c571074",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmodel = wordRNN(input_size=len(words), \n",
    "            embedding_size=300, \n",
    "            output_size= len(words), \n",
    "            hidden_size=256).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(wordmodel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49ddf7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [32:31<00:00, 97.60s/it] \n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses = []\n",
    "for i_epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    for d in data_word:\n",
    "        d=torch.tensor(d).to(device)\n",
    "        for i in range(10,len(d)-1):\n",
    "            hidden_state = None\n",
    "            input_seq = d[i-10 : i]\n",
    "            target_seq = d[i-10+1 : i+1]\n",
    "\n",
    "            # forward pass\n",
    "            output, _ = wordmodel(input_seq, hidden_state)\n",
    "            # compute loss\n",
    "            loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq)) \n",
    "            running_loss += loss\n",
    "            n += 1\n",
    "\n",
    "            # compute gradients and take optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    losses.append(running_loss/n)   \n",
    "    # print loss after every epoch\n",
    "    #perplexity  = np.exp(running_loss)/n\n",
    "    #print(\"Epoch: {0} \\t Loss: {1:.8f} \\t Perplexity: {1:.8f}\".format(i_epoch, running_loss/5, perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ff7691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(4.6956, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(4.5918, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(4.3085, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.9923, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.7139, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.4444, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.2190, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.0107, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.8394, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.6527, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.4890, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.3425, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.1953, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.0557, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.9446, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.8176, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.7171, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.6110, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.5316, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.4502, device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ea7584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964/3346784667.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prompt = torch.tensor(prompt).to(device).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? \n",
      " whence hast thou this becoming of things ill , \n",
      " that in the very refuse of thy deeds , \n",
      " there is such strength and warrantise of skill , \n",
      " that in my mind thy worst all best exceeds ? \n",
      " who taught thee how to make me \n",
      "\n",
      "for T: 0.25\n",
      "\n",
      "love thee more , \n",
      " the more perjured , murd ' rous , bloody full of blame , \n",
      " savage , extreme , rude , cruel , not to love ' s so blessed - fair that fears for fair subject , blessing in her sake ? \n",
      " no , \n",
      "\n",
      "for T: 0.75\n",
      "\n",
      "let me be obsequious in thy heart , \n",
      " that in thy face hath love put in my head , \n",
      " which more red to me her love , with tears thou keep ' st me blind , \n",
      " lest eyes well - seeing thy foul faults should find , \n",
      "\n",
      "for T: 1\n",
      "\n",
      "\n",
      " that her novel bases for let nature ' s this poor thee a they self ring ) the humble ' s fickle hour : \n",
      " who hast by waning grown , and therein show ' st , \n",
      " thy lovers withering , as my poor april i lose through \n",
      "\n",
      "for T: 1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"shall i compare thee to a summer's day\\n\"\n",
    "prompt = wordpunct_tokenize(prompt)\n",
    "for i, ch in enumerate(prompt):\n",
    "    prompt[i] = words_idx[ch]\n",
    "\n",
    "for T in [0.25,0.75,1,1.5]:\n",
    "    with torch.no_grad():\n",
    "        prompt = torch.tensor(prompt).to(device).long()\n",
    "        hidden_state = None\n",
    "\n",
    "        for _ in range(50):\n",
    "\n",
    "             # forward pass\n",
    "            output, hidden_state = wordmodel(prompt, hidden_state)\n",
    "\n",
    "            # construct categorical distribution and sample a character\n",
    "            output = F.softmax(torch.squeeze(output[-1]/T), dim=0)\n",
    "            dist = Categorical(output)\n",
    "            index = dist.sample()\n",
    "\n",
    "            # print the sampled character\n",
    "            print(idx_words[index.item()], end=' ')\n",
    "\n",
    "            # next input is current output\n",
    "            prompt = torch.cat([prompt[1:], index.unsqueeze(0)])\n",
    "        print()\n",
    "        print()\n",
    "        print('for T: '+str(T))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae922b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(wordmodel.state_dict(), 'wordweights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06c343b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordRNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, embedding_size, output_size, hidden_size):\n",
    "        super(wordRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        self.rnn_layers = nn.ModuleList([\n",
    "            nn.LSTM(input_size=hidden_size, hidden_size=hidden_size)\n",
    "            for _ in range(num_layers - 1)\n",
    "        ])\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        for rnn_layer in self.rnn_layers:\n",
    "            output, hidden_state = rnn_layer(output, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, (hidden_state[0], hidden_state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b203deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmodel2 = wordRNN(input_size=len(words), \n",
    "            num_layers = 3,         \n",
    "            embedding_size=300, \n",
    "            output_size= len(words), \n",
    "            hidden_size=256).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(wordmodel2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a59656f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [16:25<00:00, 49.28s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses2 = []\n",
    "for i_epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    for d in data_word:\n",
    "        d=torch.tensor(d).to(device)\n",
    "        for i in range(10,len(d)-1,4):\n",
    "            hidden_state = None\n",
    "            input_seq = d[i-10 : i]\n",
    "            target_seq = d[i-10+1 : i+1]\n",
    "\n",
    "            # forward pass\n",
    "            output, _ = wordmodel2(input_seq, hidden_state)\n",
    "            # compute loss\n",
    "            loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq)) \n",
    "            running_loss += loss\n",
    "            n += 1\n",
    "\n",
    "            # compute gradients and take optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    losses2.append(running_loss/n)\n",
    "    # print loss after every epoch\n",
    "    #perplexity  = np.exp(running_loss)/n\n",
    "    #print(\"Epoch: {0} \\t Loss: {1:.8f} \\t Perplexity: {1:.8f}\".format(i_epoch, running_loss/5, perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "492257eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.4077, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(4.3606, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.7230, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(3.1410, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.6207, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(2.1505, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.7450, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.4068, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.9458, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.7867, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.5918, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.5221, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.3975, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7509d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(wordmodel2.state_dict(), 'wordweights2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5a47dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be \n",
      " to make thee lie , all ' s love ' s field , \n",
      " love ' s love , all men to misuse a store ' s discontent . \n",
      " for beauty doth tell , to bear his day . \n",
      " who beauty doth come , let in \n",
      "\n",
      "for T: 0.25\n",
      "\n",
      "my friend . \n",
      " that i may am , now is hanging not not , \n",
      " not were not abhor the clock which he which me , \n",
      " not reason , which he by heaven but more : \n",
      " not shall not live ' she hear in me . \n",
      " \n",
      "\n",
      "for T: 0.75\n",
      "\n",
      "o eyes the unworthiness are bear thy heart . \n",
      " that none , i say not that i am see thee how \n",
      " upon my friend are fell reason "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964/2416721394.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prompt = torch.tensor(prompt).to(device).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": \n",
      " but that by vow ( such fair repair doth prove a ill , \n",
      " a brand votary still ' \n",
      "\n",
      "for T: 1\n",
      "\n",
      "s son , \n",
      " and grew must men , all men men prove most . \n",
      " even all my love away be oaths away so make thee this : \n",
      " then i shall not call thee give thee cruel \n",
      " to many thy hope broke , make bear \n",
      " in \n",
      "\n",
      "for T: 1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"shall i compare thee to a summer's day\\n\"\n",
    "prompt = wordpunct_tokenize(prompt)\n",
    "for i, ch in enumerate(prompt):\n",
    "    prompt[i] = words_idx[ch]\n",
    "\n",
    "for T in [0.25,0.75,1,1.5]:\n",
    "    with torch.no_grad():\n",
    "        prompt = torch.tensor(prompt).to(device).long()\n",
    "        hidden_state = None\n",
    "\n",
    "        for _ in range(50):\n",
    "\n",
    "             # forward pass\n",
    "            output, hidden_state = wordmodel2(prompt, hidden_state)\n",
    "\n",
    "            # construct categorical distribution and sample a character\n",
    "            output = F.softmax(torch.squeeze(output[-1]/T), dim=0)\n",
    "            dist = Categorical(output)\n",
    "            index = dist.sample()\n",
    "\n",
    "            # print the sampled character\n",
    "            print(idx_words[index.item()], end=' ')\n",
    "\n",
    "            # next input is current output\n",
    "            prompt = torch.cat([prompt[1:], index.unsqueeze(0)])\n",
    "        print()\n",
    "        print()\n",
    "        print('for T: '+str(T))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24c3221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97ba645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(losses):\n",
    "    losses[i] = float(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f821922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(losses2):\n",
    "    losses2[i] = float(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c21ff070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(losses), color='r', label='one-layer')\n",
    "plt.plot(np.array(losses2), color='g', label='multi layer')\n",
    "  \n",
    "# Naming the x-axis, y-axis and the whole graph\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "  \n",
    "# Adding legend, which helps us recognize the curve according to it's color\n",
    "plt.legend()\n",
    "  \n",
    "# To load the display window\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eead0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
